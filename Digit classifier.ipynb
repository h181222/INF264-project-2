{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frame the problem, and look at the big picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing hand written digits and letters by hand is very time consuming, and by automaing the process with the use of machine learning, the postal office can save recources in manpower and money. \n",
    "\n",
    "In this notebook we are going to analyze a dataset of hand written digits, and in the end be able to predict the label of the given hand written digit. We are given a dataset that contains images, and the first half of this notebook will be spent getting the data, extracting informaion from the data and then preprocessing it for further analysis by our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!pip install lightgbm\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette(\"GnBu_d\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import model_selection, preprocessing, metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from keras import backend\n",
    "from keras.models import Sequential\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = 'handwritten_digits_images.csv'\n",
    "labels = 'handwritten_digits_labels.csv'\n",
    "X = pd.read_csv(images, header=None)\n",
    "y = pd.read_csv(labels, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the data to gain insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0    1    2    3    4    5    6    7    8    9    ...  774  775  776  777  \\\n",
      "0    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "1    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "2    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "3    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "4    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "\n",
      "   778  779  780  781  782  783  \n",
      "0    0    0    0    0    0    0  \n",
      "1    0    0    0    0    0    0  \n",
      "2    0    0    0    0    0    0  \n",
      "3    0    0    0    0    0    0  \n",
      "4    0    0    0    0    0    0  \n",
      "\n",
      "[5 rows x 784 columns]\n",
      "   0\n",
      "0  0\n",
      "1  0\n",
      "2  0\n",
      "3  0\n",
      "4  0\n"
     ]
    }
   ],
   "source": [
    "print(X.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the data is not optimized for visualisation, so we need to reshape it for visualization. We use pyplot in order to show the image, and to check if it is correct we print out the corresponding label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e8212f1e80>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_data = X.values.reshape(X.shape[0], 28, 28)\n",
    "\n",
    "image_index = 69000\n",
    "print(y.iat[image_index, 0])\n",
    "plt.imshow(X_data[image_index], cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As this is an image dataset, there is not much insight to gain, but we will extract what we can, firstly, we can look at the distribution of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e8220b0978>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "axes = plt.subplots(figsize=(20,10))\n",
    "pd.value_counts(y.values.flatten(), sort=False).plot(kind=\"bar\", rot=0, legend=\"Label\", color=color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, it seems like it is pretty evenly distributed, so we won't need for example a majoriy classifier later on. We can also check what datatype our values are. This will be useful as we might have to do mathematical operations on the dataset in order to make it model-friendly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_data[image_index]))\n",
    "print(type(y.iat[image_index, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its also nice to know what shape we have for debugging purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we check if there are any null values. Since this is quite the clean dataset, we dont need to worry with replacing any values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "779    0\n",
      "780    0\n",
      "781    0\n",
      "782    0\n",
      "783    0\n",
      "Length: 784, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data to better expose the underlying data patterns to machine learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we need to reshape the data in order for it to be usable by the different models, and we also need to split the data into train and test datasets. We do that split twice in order to get a validation set. We also reshape the data to work with the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state = seed)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size= 0.2, random_state = seed)\n",
    "\n",
    "#reshaping to work with keras\n",
    "X_train_rs = X_train.values.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test_rs = X_test.values.reshape(X_test.shape[0], 28, 28, 1)\n",
    "X_val_rs= X_val.values.reshape(X_val.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to normalize the data, we need to make it possible to divide it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change reshaped values to floats\n",
    "X_train_rs = X_train_rs.astype('float32')\n",
    "X_test_rs = X_test_rs.astype('float32')\n",
    "X_val_rs= X_val_rs.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we divide by the max RGB code to normalize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing\n",
    "X_train_rs /= 255\n",
    "X_test_rs /= 255\n",
    "X_val_rs /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to one-hot encode our labels in order to use them with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encoding\n",
    "y_train_oh = to_categorical(y_train)\n",
    "y_test_oh = to_categorical(y_test)\n",
    "y_val_oh = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore different models and short-list the best ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start with, we will use an easy-to-implement model, such as DecisionTreeClassifier from Sklearn, but first we need to import some metrics to see how our models perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree = DecisionTreeClassifier(random_state=seed)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_ = decision_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8652142857142857"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, it performs ok for a model without tuning, and is considerably faster than if we had to label by hand(alebit a human would probably have a better accuracy), but we can do better. Firstly we will create a couple more models with basic configuration and no hyper-parameter tuning, then in the next part we will implement model-selection and hyper-parameter tuning. The models we will implement next are: RandomForestClassifier, Keras NN(will switch to CNN in the next part), and LightGBMClassifier(Light gradient boosted machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest = RandomForestClassifier(random_state=seed)\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_ = random_forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9411428571428572"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use a simple keras neural network, and in order to get the correct output shape, we need to flatten it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "44800/44800 [==============================] - 336s 7ms/step - loss: 0.3866 - accuracy: 0.8876\n",
      "Epoch 2/5\n",
      "44800/44800 [==============================] - 331s 7ms/step - loss: 0.3145 - accuracy: 0.9118\n",
      "Epoch 3/5\n",
      "44800/44800 [==============================] - 332s 7ms/step - loss: 0.2993 - accuracy: 0.9156\n",
      "Epoch 4/5\n",
      "44800/44800 [==============================] - 380s 8ms/step - loss: 0.2919 - accuracy: 0.9182\n",
      "Epoch 5/5\n",
      "44800/44800 [==============================] - 461s 10ms/step - loss: 0.2851 - accuracy: 0.9192\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "model = Sequential()\n",
    "model.add(Dense(784, activation=\"relu\", input_shape = X_train_rs[0].shape))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "model.compile(loss=categorical_crossentropy, optimizer=SGD(0.1), metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_rs, y_train_oh, batch_size = 16, epochs = 5)\n",
    "y_ = model.predict(X_test_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000/14000 [==============================] - 38s 3ms/step\n",
      "[0.3129837729845728, 0.915071427822113]\n"
     ]
    }
   ],
   "source": [
    "from keras.metrics import accuracy\n",
    "print(model.evaluate(X_test_rs, y_test_oh))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could try to run the code below to use XGBoost Classifier, but on multiclass classification it seems that the time increases quadratically with the number of classes(took me ish 1 hour to run on my desktop computer). Instead we will use LightGBM which is also a gradient boosted machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from xgboost import XGBClassifier\n",
    "#model = XGBClassifier()\n",
    "#model.fit(X_train, y_train)\n",
    "\n",
    "#print(model)\n",
    "\n",
    "#y_ = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import lightgbm as lgbm\n",
    "model = lgbm.LGBMClassifier(objective='multiclass',silent=False, random_state = seed)\n",
    "model.fit(X_train, y_train)\n",
    "y_ = model.predict(X_test)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, y_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty good score here! But we can make it better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune models and combine them to a good solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is all about fine tuning our models, as well as selecting the best one. We are going to implement model selection, as well as an \"ensemble\" of all our models into one to see if it gives us the highest score in this notebook. Firstly we will see how we can improve RandomForest and DecisionTree, then we will make a Convolutional Neural-Network with keras, and lastly do some fine tuning on the hyper parameters for LightGBM. We start out by implementing kfolds cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KFold_split(X, Y, num_folds, seed):\n",
    "    KFold_splitter = KFold(n_splits=num_folds, shuffle=True, random_state=seed)\n",
    "    X_train_folds = []\n",
    "    X_val_folds = []\n",
    "    Y_train_folds = []\n",
    "    Y_val_folds = []\n",
    "    for (kth_fold_train_idxs, kth_fold_val_idxs) in KFold_splitter.split(X, Y):\n",
    "        X_train_folds.append(X[kth_fold_train_idxs])\n",
    "        X_val_folds.append(X[kth_fold_val_idxs])\n",
    "        Y_train_folds.append(Y[kth_fold_train_idxs])\n",
    "        Y_val_folds.append(Y[kth_fold_val_idxs])\n",
    "    return X_train_folds, X_val_folds, Y_train_folds, Y_val_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KFold_model_selection(X, Y, models, num_folds, hyperparameters, seed):\n",
    "    X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y, test_size = 0.2)\n",
    "    X_train_folds, X_val_folds, Y_train_folds, Y_val_folds = KFold_split(X, Y, num_folds, seed)\n",
    "    accuracy_scores = []\n",
    "    foridx = 0\n",
    "    for hyperparameter in hyperparameters:\n",
    "        print(\"\\nNow preprocessing model\", Type(hyperparameter[0]))\n",
    "        accuracy_score = perform_KFold_CV(X_train_folds, X_val_folds, Y_train_folds, Y_val_folds, hyperparameter, foridx)\n",
    "        print(\"Mean accuracy score:\", accuracy_score)\n",
    "        accuray_scores.append(accuracy_score)\n",
    "        foridx += 1\n",
    "\n",
    "    min_val = np.min(accuracy_scores)\n",
    "    best_model_idx = accuracy_scores.index(min_val)\n",
    "    best_model = hyperparameters[best_model_idx]\n",
    "    print(\"\\n\\nBest model:\", best_model)\n",
    "\n",
    "    best_model_test_F1 = min_val\n",
    "    print(\"Test F1:\", best_model_test_accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_KFold_CV(X_train_folds, X_val_folds, Y_train_folds, Y_val_folds, hyperparameter, model_idx):\n",
    "    val_fold_accuracy_scores = []\n",
    "    cmpt = 0\n",
    "    # For each fold, assess a surrogate model with fixed hyper-parameters:\n",
    "    for X_train_fold, X_val_fold, Y_train_fold, Y_val_fold in zip(X_train_folds, X_val_folds, Y_train_folds, Y_val_folds):\n",
    "        val_fold_accuracy_score = assess_model(X_train_fold, X_val_fold, Y_train_fold, Y_val_fold, hyperparameter, model_idx)\n",
    "        cmpt += 1\n",
    "        print(\"Surrogate model\", str(cmpt) + \"/\" + str(len(X_val_folds)), \"validation accuracy score:\", val_fold_accuracy_score)\n",
    "        val_fold_accuracy_scores.append(val_fold_accuracy_score)\n",
    "    mean_accuracy_score = np.mean(val_fold_accuracy_scores)\n",
    "    return mean_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_model(X_train, X_test, y_train, y_test, model):\n",
    "    if(model[0] == DecisionTreeClassifier()):\n",
    "        clf = DecisionTreeClassifier(max_depth = hyperparameter[0], )\n",
    "    elif(model[0] == RandomForestClassifier()):\n",
    "        clf = model[0]\n",
    "    elif(model[0] == lgbm.LGBMClassifier()):\n",
    "        clf = model[0]\n",
    "        clf = clf(objective='multiclass',silent=False, random_state = seed, learning_rate=model[1], )\n",
    "    if(model[0] != Sequential()):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_ = model.predict(X_test)\n",
    "        accuracy_score = accuracy_score(y_test, y_)\n",
    "    else:\n",
    "        model.fit(X_train_rs, y_train_oh)\n",
    "        y_ = model.predict(X_test_rs)\n",
    "        accuracy_score = model.evaluate(y_test_oh)\n",
    "    return accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_parameters_instances = {\"0\": [DecisionTreeClassifier(), range(2,20), 0.05],\n",
    "                              \"1\": [RandomForestClassifier(), 5, 0.05],\n",
    "                              \"2\": [lgbm.LGBMClassifier,(0.01), 0.07]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_pipeline(X_train, y_train, X_test, y_test, model, params, cv=10, scoring='mean_squared_error'):\n",
    "    grid = GridSearchCV(estimator=model, param_grid=params, cv=cv, n_jobs=-1, scoring=scoring, verbose=2)\n",
    "    clf = grid.fit(X_train, y_train)\n",
    "    \n",
    "    pred = clf.predict(X_test)\n",
    "    \n",
    "    return clf, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2916 candidates, totalling 14580 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 47.9min\n"
     ]
    }
   ],
   "source": [
    "model = lgbm.LGBMClassifier()\n",
    "param_grid = {\n",
    "    'n_estimators': [400, 800, 1000],\n",
    "    'colsample:bytree': [0.7, 0.8],\n",
    "    'max_depth': [15, 21, 26],\n",
    "    'reg_lambda': [1.1, 1.2, 1.3],\n",
    "    'reg_alpha': [1.1, 1.2, 1.3],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'subsample_freq': [20],\n",
    "    'num_leaves': [100, 150, 200],\n",
    "    'min_split_gain': [0.3, 0.4]\n",
    "}\n",
    "\n",
    "model, pred = hyperparameter_pipeline(X_train, y_train, X_test, y_test, model, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "print(model.best_score_)\n",
    "print(model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try a bit more advanced neural network with more epochs, and using the adam optimizer instead of stochastic gradient descent. I thought about including it in the kfold CV, but i'd rather do it manually, and walk you through the steps i made before coming up with this solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#model.add(Conv2D(28, kernel_size=(3, 3), input_shape=X_train_rs[0].shape))\n",
    "#model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(280, activation=\"relu\"))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.add(Conv2D(32,kernel_size=3,activation='relu',input_shape=(28,28,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32,kernel_size=3,activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(20,kernel_size=5,strides=2,padding='same',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=categorical_crossentropy, metrics=['accuracy'])\n",
    "model.fit(X_train_rs, y_train_oh, epochs = 15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate and present solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_val_rs, y_val_oh)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
